{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "performance  = pd.read_csv('train/performance_train.csv', index_col= False)\n",
    "facturation  = pd.read_csv('train/facturation_train.csv', index_col= False)\n",
    "paiements    = pd.read_csv('train/paiements_train.csv', index_col= False)\n",
    "transactions = pd.read_csv('train/transactions_train.csv', index_col= False)\n",
    "#load test dataset\n",
    "performance_test  = pd.read_csv('test/performance_test.csv', index_col= False)\n",
    "facturation_test  = pd.read_csv('test/facturation_test.csv', index_col= False)\n",
    "paiements_test    = pd.read_csv('test/paiements_test.csv', index_col= False)\n",
    "transactions_test = pd.read_csv('test/transactions_test.csv', index_col= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paiements.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_by_ID(dataframe):\n",
    "    output = {}\n",
    "    DECISION_keys = dataframe[\"DECISION_XCD\"].value_counts().keys()\n",
    "    TRANSACTION_C_keys = dataframe[\"TRANSACTION_CATEGORY_XCD\"].value_counts().keys()\n",
    "    TRANSACTION_T_keys = dataframe[\"TRANSACTION_TYPE_XCD\"].value_counts().keys()\n",
    "    cmt = dataframe[\"cred_minus_transaction_net_positive\"].value_counts().keys()\n",
    "    SICGROUP_keys = dataframe[\"SICGROUP\"].value_counts().keys()\n",
    "    for i in dataframe[\"ID_CPTE\"].value_counts().keys():        \n",
    "        subframe = dataframe.loc[dataframe[\"ID_CPTE\"] == i]\n",
    "        #query for DECISION_XCD\n",
    "        DECISION_dict = {}\n",
    "        for j in DECISION_keys:\n",
    "            s = \"DECISION_XCD_\" + j\n",
    "            try:\n",
    "                DECISION_dict[s] = subframe[\"DECISION_XCD\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                DECISION_dict[s] = 0\n",
    "        #query for transaction_c\n",
    "        TRANSACTION_C_dict = {}\n",
    "        for j in TRANSACTION_C_keys:\n",
    "            s = \"TRANSACTION_C_\" + j\n",
    "            try:\n",
    "                TRANSACTION_C_dict[s] = subframe[\"TRANSACTION_CATEGORY_XCD\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                TRANSACTION_C_dict[s] = 0\n",
    "        TRANSACTION_T_dict = {}\n",
    "        #query for transaction_t    \n",
    "        for j in TRANSACTION_T_keys:\n",
    "            s = \"TRANSACTION_T_\" + j\n",
    "            try:\n",
    "                TRANSACTION_T_dict[s] = subframe[\"TRANSACTION_TYPE_XCD\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                TRANSACTION_T_dict[s] = 0\n",
    "        #query for SICGROUP\n",
    "        SICGROUP_dict = {}\n",
    "\n",
    "        for j in SICGROUP_keys:\n",
    "            s = \"SCIGROUP_\" + j\n",
    "            try:\n",
    "                SICGROUP_dict[s] = subframe[\"SICGROUP\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                SICGROUP_dict[s] = 0\n",
    "        CMT_dict = {}\n",
    "        for j in cmt:\n",
    "            s = \"cred_minus_transaction_net_positive\" + str(j)\n",
    "            try:\n",
    "                CMT_dict[s] = subframe[\"cred_minus_transaction_net_positive\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                CMT_dict[s] = 0\n",
    "                \n",
    "        output[i] = [DECISION_dict, TRANSACTION_C_dict, TRANSACTION_T_dict, SICGROUP_dict, CMT_dict]\n",
    "    return output\n",
    "def summarize_by_ID_2(dataframe):\n",
    "    output = {}\n",
    "    PAYMENT_REVERSAL_XFLG_key =  dataframe[\"PAYMENT_REVERSAL_XFLG\"].value_counts().keys()\n",
    "    for i in dataframe[\"ID_CPTE\"].value_counts().keys():        \n",
    "        subframe = dataframe.loc[dataframe[\"ID_CPTE\"] == i]\n",
    "        TRANSACTION_SUM_dict = {}\n",
    "        TRANSACTION_SUM_dict[\"TRANSACTION_AMT_sum\"] = subframe[\"TRANSACTION_AMT\"].sum()\n",
    "\n",
    "        PAYMENT_REVERSAL_XFLG_dict = {}\n",
    "        for j in PAYMENT_REVERSAL_XFLG_key:\n",
    "            s = \"PAYMENT_REVERSAL_XFLG_key_\" + str(j)\n",
    "            try:\n",
    "                PAYMENT_REVERSAL_XFLG_dict[s] = subframe[\"PAYMENT_REVERSAL_XFLG\"].value_counts(normalize=True)[j]\n",
    "            except:\n",
    "                PAYMENT_REVERSAL_XFLG_dict[s] = 0   \n",
    "        output[i] = [TRANSACTION_SUM_dict,PAYMENT_REVERSAL_XFLG_dict]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ID_of_defaults = performance.loc[performance[\"Default\"] == 1][\"ID_CPTE\"]\n",
    "#Uniform across all years so drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineering(performance,paiements,transactions,test):\n",
    "    performance[\"PERIODID_MY\"]= pd.to_datetime(performance[\"PERIODID_MY\"]).dt.year\n",
    "    #Get rid of BS features\n",
    "    transaction_dropped = transactions.drop([\"MERCHANT_CITY_NAME\",\"MERCHANT_CATEGORY_XCD\",\"MERCHANT_COUNTRY_XCD\", \"TRANSACTION_DTTM\"],1)\n",
    "    \n",
    "    ## add credit limit minus transaction amount and drop credit limit, transaction amount\n",
    "    cred_minus_transaction = transaction_dropped[\"PRIOR_CREDIT_LIMIT_AMT\"].sub(transaction_dropped[\"TRANSACTION_AMT\"])\n",
    "    transaction_dropped = transaction_dropped.drop([\"PRIOR_CREDIT_LIMIT_AMT\", \"TRANSACTION_AMT\"],1)\n",
    "    transaction_dropped['cred_minus_transaction'] = cred_minus_transaction\n",
    "    \n",
    "    # drop cred_minus_transaction and query whether it is positive\n",
    "    transaction_dropped[\"cred_minus_transaction_net_positive\"] = transaction_dropped[\"cred_minus_transaction\"].ge(0)\n",
    "    transaction_dropped = transaction_dropped.drop([\"cred_minus_transaction\"],1)\n",
    "    \n",
    "    ##Create cleaned dataframe for transaction \n",
    "    output = summarize_by_ID(transaction_dropped)\n",
    "    convert = {}\n",
    "    s = pd.Series()\n",
    "    for i in output.keys():\n",
    "        for k in output[i]:\n",
    "            s= {**s,**k}\n",
    "        convert[i] = pd.Series(s)\n",
    "    final = pd.DataFrame.from_dict(convert, orient='index')\n",
    "    \n",
    "    #create cleaned dataframe for payments\n",
    "\n",
    "    paiements_drop = paiements.drop([\"TRANSACTION_DTTM\"],1)\n",
    "    \n",
    "    output2 = summarize_by_ID_2(paiements_drop)\n",
    "    convert2 = {}\n",
    "    s2 = pd.Series()\n",
    "    for i in output2.keys():\n",
    "        for k2 in output2[i]:\n",
    "            s2= {**s2,**k2}\n",
    "        convert2[i] = pd.Series(s2)    \n",
    "    final2 = pd.DataFrame.from_dict(convert2, orient='index')\n",
    "    \n",
    "    #create cleaned dataframe for performance\n",
    "    temp = performance.set_index(\"ID_CPTE\")\n",
    "    del temp.index.name\n",
    "    \n",
    "    combined = final2.combine_first(final.combine_first(temp))\n",
    "    if (not test):\n",
    "        combined_drop_features = combined[[\"cred_minus_transaction_net_positiveTrue\",\"Default\", \"PAYMENT_REVERSAL_XFLG_key_Q\"]]\n",
    "    else:\n",
    "        combined_drop_features = combined[[\"cred_minus_transaction_net_positiveTrue\", \"PAYMENT_REVERSAL_XFLG_key_Q\"]]\n",
    "        \n",
    "    return combined_drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputing(dataset_train_x, imputee):\n",
    "    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "    imp = imp.fit(dataset_train_x)\n",
    "    return imp.transform(imputee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient_boosting_classifier(train,test):\n",
    "    space  = [Integer(2, 200, name='max_depth'),\n",
    "              Real(10**-5, 10**0, \"log-uniform\", name='learning_rate'),\n",
    "              Integer(1, train_x.shape[1], name='max_features'),\n",
    "              Integer(2, 100, name='min_samples_split'),\n",
    "              Integer(1, 100, name='min_samples_leaf')]    \n",
    "    @use_named_args(space)\n",
    "    def objective(**params):\n",
    "        reg.set_params(**params)\n",
    "\n",
    "        return -np.mean(cross_val_score(reg, train,test , cv=5, n_jobs=-1,\n",
    "                                        scoring=\"neg_mean_absolute_error\"))\n",
    "    reg = GradientBoostingClassifier(n_estimators=50, random_state=0)\n",
    "\n",
    "    res_gp = gp_minimize(objective, space, n_calls=50, random_state=0)\n",
    "    return GradientBoostingClassifier(n_estimators=50, random_state=0, max_depth = res_gp.x[0], \n",
    "                                      learning_rate = res_gp.x[1], max_features = res_gp.x[2], min_samples_split = res_gp.x[3]\n",
    "                                     ,min_samples_leaf= res_gp.x[4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(classifier, X):\n",
    "    return classifier.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submission_creator(ID, default):\n",
    "    return pd.concat([pd.DataFrame(ID),pd.DataFrame(default)],axis =1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_write(dataframe):\n",
    "    dataframe.to_csv(\"submission.csv\", index=False, header =['ID_CPTE', 'Default'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "imputing() missing 1 required positional argument: 'imputee'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-512-4243d95742f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvalid_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Default\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#imputation#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_x_imp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: imputing() missing 1 required positional argument: 'imputee'"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_train = feature_engineering(performance,paiements,transactions, False)\n",
    "\n",
    "#whole dataset split x,y\n",
    "dataset_train_x, dataset_train_y =  dataset_train.drop([\"Default\"],1), dataset_train[\"Default\"]\n",
    "\n",
    "##### Training dataset created #####\n",
    "#dataset split training and validation\n",
    "\n",
    "train, valid = train_test_split(dataset_train, test_size=0.2)\n",
    "train_y = train[\"Default\"]\n",
    "train_x = train.drop([\"Default\"],1)\n",
    "valid_y = valid[\"Default\"]\n",
    "valid_x = valid.drop([\"Default\"],1)\n",
    "#imputation#\n",
    "train_x_imp, valid_x_imp = imputing(dataset_train_x,train_x), imputing(dataset_train_x,valid_x)\n",
    "dataset_train_x_imp = imputing(dataset_train_x,dataset_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_test = feature_engineering(performance_test,paiements_test,transactions_test, True)\n",
    "dataset_test_imputed = imputing(dataset_train_x,dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n",
      "/Users/peterpark/anaconda3/lib/python3.5/site-packages/skopt/optimizer/optimizer.py:399: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-532-7301c7811efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#bestGBclassifier.fit(train_x_imp, train_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mGB_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestGBclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_x_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msubmission_GB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGB_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-510-90c3a446d3bf>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(classifier, X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \"\"\"\n\u001b[0;32m-> 1532\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \"\"\"\n\u001b[1;32m   1486\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;31m# for use in inner loop, not raveling the output in single-class case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# not doing input validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_init_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;34m\"\"\"Check input and compute prediction of ``init``. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_check_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;34m\"\"\"Check that the estimator is initialized, raising an error if not.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "## Gradient boosting model selection and submission\n",
    "bestGBclassifier = gradient_boosting_classifier(dataset_train_x_imp,dataset_train_y)\n",
    "ID = pd.Series(dataset_test.index)\n",
    "bestGBclassifier.fit(train_x_imp, train_y)\n",
    "GB_prediction = prediction(bestGBclassifier,valid_x_imp)\n",
    "submission_GB = submission_creator(ID,GB_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GB_prediction = prediction(bestGBclassifier,dataset_test_imputed)\n",
    "submission_GB = submission_creator(ID,GB_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## write_csv\n",
    "csv_write(submission_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
